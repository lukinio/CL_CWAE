Files already downloaded and verified
Files already downloaded and verified
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
CNN(
  (c1): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (c2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (c3): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fc1): Sequential(
    (0): Linear(in_features=2048, out_features=256, bias=True)
    (1): ReLU()
  )
  (last): ModuleDict(
    (1): Linear(in_features=256, out_features=2, bias=True)
    (2): Linear(in_features=256, out_features=2, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
    (5): Linear(in_features=256, out_features=2, bias=True)
  )
)
#parameter of model: 962858
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
* TRAIN - Accuracy 80.822 Loss 0.4039
* VALID - Accuracy 88.590 Loss 0.2743
Epoch:1
LR: 0.001
* TRAIN - Accuracy 89.078 Loss 0.2545
* VALID - Accuracy 90.720 Loss 0.2247
Epoch:2
LR: 0.001
* TRAIN - Accuracy 91.734 Loss 0.1981
* VALID - Accuracy 93.060 Loss 0.1720
Epoch:3
LR: 0.001
* TRAIN - Accuracy 92.868 Loss 0.1741
* VALID - Accuracy 92.900 Loss 0.1789
Epoch:4
LR: 0.001
* TRAIN - Accuracy 93.500 Loss 0.1573
* VALID - Accuracy 93.020 Loss 0.1717
Epoch:5
LR: 0.001
* TRAIN - Accuracy 94.222 Loss 0.1443
* VALID - Accuracy 92.980 Loss 0.1777
Epoch:6
LR: 0.001
* TRAIN - Accuracy 94.876 Loss 0.1297
* VALID - Accuracy 94.410 Loss 0.1450
Epoch:7
LR: 0.001
* TRAIN - Accuracy 95.204 Loss 0.1212
* VALID - Accuracy 94.990 Loss 0.1258
Epoch:8
LR: 0.001
* TRAIN - Accuracy 95.570 Loss 0.1132
* VALID - Accuracy 94.800 Loss 0.1310
Epoch:9
LR: 0.001
* TRAIN - Accuracy 95.822 Loss 0.1049
* VALID - Accuracy 95.480 Loss 0.1195
Epoch:10
LR: 0.001
* TRAIN - Accuracy 96.034 Loss 0.0993
* VALID - Accuracy 94.720 Loss 0.1437
Epoch:11
LR: 0.001
* TRAIN - Accuracy 96.424 Loss 0.0917
* VALID - Accuracy 95.390 Loss 0.1222
* VALID - Accuracy 95.390 Loss 0.1222
OrderedDict([('All', {'All': 95.39})])
Task All average acc: 95.39
===Summary of experiment repeats: 1 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [95.39  0.    0.    0.    0.    0.    0.    0.    0.    0.  ]
mean: 9.539 std: 28.617
Files already downloaded and verified
Files already downloaded and verified
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
CNN(
  (c1): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (c2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (c3): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fc1): Sequential(
    (0): Linear(in_features=2048, out_features=256, bias=True)
    (1): ReLU()
  )
  (last): ModuleDict(
    (1): Linear(in_features=256, out_features=2, bias=True)
    (2): Linear(in_features=256, out_features=2, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
    (5): Linear(in_features=256, out_features=2, bias=True)
  )
)
#parameter of model: 962858
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
* TRAIN - Accuracy 80.646 Loss 0.4111
* VALID - Accuracy 73.350 Loss 0.6299
Epoch:1
LR: 0.001
* TRAIN - Accuracy 89.300 Loss 0.2479
* VALID - Accuracy 87.470 Loss 0.2975
Epoch:2
LR: 0.001
* TRAIN - Accuracy 91.878 Loss 0.1987
* VALID - Accuracy 91.540 Loss 0.2078
Epoch:3
LR: 0.001
* TRAIN - Accuracy 92.938 Loss 0.1745
* VALID - Accuracy 90.850 Loss 0.2218
Epoch:4
LR: 0.001
* TRAIN - Accuracy 93.640 Loss 0.1572
* VALID - Accuracy 93.510 Loss 0.1597
Epoch:5
LR: 0.001
* TRAIN - Accuracy 94.030 Loss 0.1474
* VALID - Accuracy 93.830 Loss 0.1626
Epoch:6
LR: 0.001
* TRAIN - Accuracy 94.698 Loss 0.1341
* VALID - Accuracy 94.050 Loss 0.1515
Epoch:7
LR: 0.001
* TRAIN - Accuracy 95.098 Loss 0.1223
* VALID - Accuracy 94.940 Loss 0.1316
Epoch:8
LR: 0.001
* TRAIN - Accuracy 95.386 Loss 0.1160
* VALID - Accuracy 93.010 Loss 0.1978
Epoch:9
LR: 0.001
* TRAIN - Accuracy 95.832 Loss 0.1056
* VALID - Accuracy 93.760 Loss 0.1669
Epoch:10
LR: 0.001
* TRAIN - Accuracy 96.016 Loss 0.1009
* VALID - Accuracy 94.600 Loss 0.1417
Epoch:11
LR: 0.001
* TRAIN - Accuracy 96.322 Loss 0.0946
* VALID - Accuracy 95.470 Loss 0.1174
* VALID - Accuracy 95.470 Loss 0.1174
OrderedDict([('All', {'All': 95.47})])
Task All average acc: 95.47
===Summary of experiment repeats: 2 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [95.39 95.47  0.    0.    0.    0.    0.    0.    0.    0.  ]
mean: 19.086000000000002 std: 38.17200419155379
Files already downloaded and verified
Files already downloaded and verified
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
CNN(
  (c1): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (c2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (c3): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fc1): Sequential(
    (0): Linear(in_features=2048, out_features=256, bias=True)
    (1): ReLU()
  )
  (last): ModuleDict(
    (1): Linear(in_features=256, out_features=2, bias=True)
    (2): Linear(in_features=256, out_features=2, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
    (5): Linear(in_features=256, out_features=2, bias=True)
  )
)
#parameter of model: 962858
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
* TRAIN - Accuracy 81.542 Loss 0.3941
* VALID - Accuracy 87.820 Loss 0.2825
Epoch:1
LR: 0.001
* TRAIN - Accuracy 89.588 Loss 0.2475
* VALID - Accuracy 90.450 Loss 0.2255
Epoch:2
LR: 0.001
* TRAIN - Accuracy 91.852 Loss 0.1984
* VALID - Accuracy 90.080 Loss 0.2475
Epoch:3
LR: 0.001
* TRAIN - Accuracy 92.830 Loss 0.1738
* VALID - Accuracy 91.130 Loss 0.2157
Epoch:4
LR: 0.001
* TRAIN - Accuracy 93.436 Loss 0.1599
* VALID - Accuracy 91.510 Loss 0.2154
Epoch:5
LR: 0.001
* TRAIN - Accuracy 94.432 Loss 0.1414
* VALID - Accuracy 91.830 Loss 0.2129
Epoch:6
LR: 0.001
* TRAIN - Accuracy 94.930 Loss 0.1291
* VALID - Accuracy 94.570 Loss 0.1544
Epoch:7
LR: 0.001
* TRAIN - Accuracy 95.240 Loss 0.1201
* VALID - Accuracy 94.390 Loss 0.1463
Epoch:8
LR: 0.001
* TRAIN - Accuracy 95.590 Loss 0.1124
* VALID - Accuracy 94.450 Loss 0.1517
Epoch:9
LR: 0.001
* TRAIN - Accuracy 95.868 Loss 0.1046
* VALID - Accuracy 95.020 Loss 0.1301
Epoch:10
LR: 0.001
* TRAIN - Accuracy 96.258 Loss 0.0970
* VALID - Accuracy 95.640 Loss 0.1179
Epoch:11
LR: 0.001
* TRAIN - Accuracy 96.432 Loss 0.0917
* VALID - Accuracy 95.420 Loss 0.1182
* VALID - Accuracy 95.420 Loss 0.1182
OrderedDict([('All', {'All': 95.42})])
Task All average acc: 95.42
===Summary of experiment repeats: 3 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [95.39 95.47 95.42  0.    0.    0.    0.    0.    0.    0.  ]
mean: 28.628000000000004 std: 43.729996066773204
Files already downloaded and verified
Files already downloaded and verified
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
CNN(
  (c1): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (c2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (c3): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fc1): Sequential(
    (0): Linear(in_features=2048, out_features=256, bias=True)
    (1): ReLU()
  )
  (last): ModuleDict(
    (1): Linear(in_features=256, out_features=2, bias=True)
    (2): Linear(in_features=256, out_features=2, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
    (5): Linear(in_features=256, out_features=2, bias=True)
  )
)
#parameter of model: 962858
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
* TRAIN - Accuracy 82.152 Loss 0.3822
* VALID - Accuracy 86.760 Loss 0.3154
Epoch:1
LR: 0.001
* TRAIN - Accuracy 89.914 Loss 0.2402
* VALID - Accuracy 88.480 Loss 0.2858
Epoch:2
LR: 0.001
* TRAIN - Accuracy 91.948 Loss 0.1955
* VALID - Accuracy 93.100 Loss 0.1720
Epoch:3
LR: 0.001
* TRAIN - Accuracy 93.054 Loss 0.1702
* VALID - Accuracy 93.230 Loss 0.1684
Epoch:4
LR: 0.001
* TRAIN - Accuracy 93.672 Loss 0.1548
* VALID - Accuracy 92.950 Loss 0.1807
Epoch:5
LR: 0.001
* TRAIN - Accuracy 94.292 Loss 0.1430
* VALID - Accuracy 93.690 Loss 0.1594
Epoch:6
LR: 0.001
* TRAIN - Accuracy 94.970 Loss 0.1301
* VALID - Accuracy 94.020 Loss 0.1588
Epoch:7
LR: 0.001
* TRAIN - Accuracy 95.276 Loss 0.1201
* VALID - Accuracy 94.840 Loss 0.1359
Epoch:8
LR: 0.001
* TRAIN - Accuracy 95.524 Loss 0.1130
* VALID - Accuracy 94.220 Loss 0.1507
Epoch:9
LR: 0.001
* TRAIN - Accuracy 95.928 Loss 0.1051
* VALID - Accuracy 94.730 Loss 0.1439
Epoch:10
LR: 0.001
* TRAIN - Accuracy 96.300 Loss 0.0964
* VALID - Accuracy 95.420 Loss 0.1247
Epoch:11
LR: 0.001
* TRAIN - Accuracy 96.468 Loss 0.0919
* VALID - Accuracy 95.450 Loss 0.1262
* VALID - Accuracy 95.450 Loss 0.1262
OrderedDict([('All', {'All': 95.45})])
Task All average acc: 95.45
===Summary of experiment repeats: 4 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [95.39 95.47 95.42 95.45  0.    0.    0.    0.    0.    0.  ]
mean: 38.173 std: 46.752189905928475
Files already downloaded and verified
Files already downloaded and verified
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
CNN(
  (c1): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (c2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (c3): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fc1): Sequential(
    (0): Linear(in_features=2048, out_features=256, bias=True)
    (1): ReLU()
  )
  (last): ModuleDict(
    (1): Linear(in_features=256, out_features=2, bias=True)
    (2): Linear(in_features=256, out_features=2, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
    (5): Linear(in_features=256, out_features=2, bias=True)
  )
)
#parameter of model: 962858
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
* TRAIN - Accuracy 81.174 Loss 0.3995
* VALID - Accuracy 85.570 Loss 0.3317
Epoch:1
LR: 0.001
* TRAIN - Accuracy 89.158 Loss 0.2582
* VALID - Accuracy 90.220 Loss 0.2390
Epoch:2
LR: 0.001
* TRAIN - Accuracy 91.790 Loss 0.2002
* VALID - Accuracy 92.090 Loss 0.1958
Epoch:3
LR: 0.001
* TRAIN - Accuracy 92.882 Loss 0.1761
* VALID - Accuracy 92.110 Loss 0.1993
Epoch:4
LR: 0.001
* TRAIN - Accuracy 93.894 Loss 0.1540
* VALID - Accuracy 91.210 Loss 0.2248
Epoch:5
LR: 0.001
* TRAIN - Accuracy 94.360 Loss 0.1405
* VALID - Accuracy 92.370 Loss 0.1913
Epoch:6
LR: 0.001
* TRAIN - Accuracy 94.844 Loss 0.1285
* VALID - Accuracy 94.370 Loss 0.1514
Epoch:7
LR: 0.001
* TRAIN - Accuracy 95.278 Loss 0.1188
* VALID - Accuracy 95.030 Loss 0.1276
Epoch:8
LR: 0.001
* TRAIN - Accuracy 95.738 Loss 0.1089
* VALID - Accuracy 94.380 Loss 0.1499
Epoch:9
LR: 0.001
* TRAIN - Accuracy 95.934 Loss 0.1024
* VALID - Accuracy 95.210 Loss 0.1221
Epoch:10
LR: 0.001
* TRAIN - Accuracy 96.290 Loss 0.0953
* VALID - Accuracy 95.240 Loss 0.1253
Epoch:11
LR: 0.001
* TRAIN - Accuracy 96.542 Loss 0.0893
* VALID - Accuracy 95.410 Loss 0.1287
* VALID - Accuracy 95.410 Loss 0.1287
OrderedDict([('All', {'All': 95.41})])
Task All average acc: 95.41
===Summary of experiment repeats: 5 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [95.39 95.47 95.42 95.45 95.41  0.    0.    0.    0.    0.  ]
mean: 47.714 std: 47.714004275474515
Files already downloaded and verified
Files already downloaded and verified
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
CNN(
  (c1): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (c2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (c3): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fc1): Sequential(
    (0): Linear(in_features=2048, out_features=256, bias=True)
    (1): ReLU()
  )
  (last): ModuleDict(
    (1): Linear(in_features=256, out_features=2, bias=True)
    (2): Linear(in_features=256, out_features=2, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
    (5): Linear(in_features=256, out_features=2, bias=True)
  )
)
#parameter of model: 962858
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
* TRAIN - Accuracy 81.578 Loss 0.3925
* VALID - Accuracy 88.350 Loss 0.2710
Epoch:1
LR: 0.001
* TRAIN - Accuracy 89.612 Loss 0.2444
* VALID - Accuracy 91.170 Loss 0.2084
Epoch:2
LR: 0.001
* TRAIN - Accuracy 91.956 Loss 0.1959
* VALID - Accuracy 92.730 Loss 0.1816
Epoch:3
LR: 0.001
* TRAIN - Accuracy 93.066 Loss 0.1692
* VALID - Accuracy 93.890 Loss 0.1631
Epoch:4
LR: 0.001
* TRAIN - Accuracy 93.828 Loss 0.1527
* VALID - Accuracy 94.210 Loss 0.1527
Epoch:5
LR: 0.001
* TRAIN - Accuracy 94.618 Loss 0.1367
* VALID - Accuracy 93.810 Loss 0.1553
Epoch:6
LR: 0.001
* TRAIN - Accuracy 95.044 Loss 0.1258
* VALID - Accuracy 95.070 Loss 0.1259
Epoch:7
LR: 0.001
* TRAIN - Accuracy 95.412 Loss 0.1158
* VALID - Accuracy 94.550 Loss 0.1384
Epoch:8
LR: 0.001
* TRAIN - Accuracy 95.790 Loss 0.1082
* VALID - Accuracy 94.150 Loss 0.1617
Epoch:9
LR: 0.001
* TRAIN - Accuracy 95.950 Loss 0.1031
* VALID - Accuracy 94.710 Loss 0.1463
Epoch:10
LR: 0.001
* TRAIN - Accuracy 96.310 Loss 0.0950
* VALID - Accuracy 94.940 Loss 0.1354
Epoch:11
LR: 0.001
* TRAIN - Accuracy 96.570 Loss 0.0888
* VALID - Accuracy 95.180 Loss 0.1302
* VALID - Accuracy 95.180 Loss 0.1302
OrderedDict([('All', {'All': 95.18})])
Task All average acc: 95.18
===Summary of experiment repeats: 6 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [95.39 95.47 95.42 95.45 95.41 95.18  0.    0.    0.    0.  ]
mean: 57.232000000000006 std: 46.7297915253214
Files already downloaded and verified
Files already downloaded and verified
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
CNN(
  (c1): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (c2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (c3): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fc1): Sequential(
    (0): Linear(in_features=2048, out_features=256, bias=True)
    (1): ReLU()
  )
  (last): ModuleDict(
    (1): Linear(in_features=256, out_features=2, bias=True)
    (2): Linear(in_features=256, out_features=2, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
    (5): Linear(in_features=256, out_features=2, bias=True)
  )
)
#parameter of model: 962858
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
* TRAIN - Accuracy 81.352 Loss 0.3976
* VALID - Accuracy 83.560 Loss 0.3753
Epoch:1
LR: 0.001
* TRAIN - Accuracy 89.800 Loss 0.2432
* VALID - Accuracy 88.790 Loss 0.2699
Epoch:2
LR: 0.001
* TRAIN - Accuracy 91.940 Loss 0.1971
* VALID - Accuracy 91.130 Loss 0.2301
Epoch:3
LR: 0.001
* TRAIN - Accuracy 93.018 Loss 0.1719
* VALID - Accuracy 93.060 Loss 0.1701
Epoch:4
LR: 0.001
* TRAIN - Accuracy 94.012 Loss 0.1505
* VALID - Accuracy 93.290 Loss 0.1708
Epoch:5
LR: 0.001
* TRAIN - Accuracy 94.756 Loss 0.1345
* VALID - Accuracy 94.310 Loss 0.1451
Epoch:6
LR: 0.001
* TRAIN - Accuracy 94.954 Loss 0.1275
* VALID - Accuracy 94.650 Loss 0.1424
Epoch:7
LR: 0.001
* TRAIN - Accuracy 95.484 Loss 0.1166
* VALID - Accuracy 93.690 Loss 0.1629
Epoch:8
LR: 0.001
* TRAIN - Accuracy 95.800 Loss 0.1073
* VALID - Accuracy 95.350 Loss 0.1232
Epoch:9
LR: 0.001
* TRAIN - Accuracy 96.112 Loss 0.1009
* VALID - Accuracy 95.110 Loss 0.1280
Epoch:10
LR: 0.001
* TRAIN - Accuracy 96.286 Loss 0.0961
* VALID - Accuracy 95.370 Loss 0.1270
Epoch:11
LR: 0.001
* TRAIN - Accuracy 96.590 Loss 0.0868
* VALID - Accuracy 95.830 Loss 0.1183
* VALID - Accuracy 95.830 Loss 0.1183
OrderedDict([('All', {'All': 95.83})])
Task All average acc: 95.83
===Summary of experiment repeats: 7 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [95.39 95.47 95.42 95.45 95.41 95.18 95.83  0.    0.    0.  ]
mean: 66.81500000000001 std: 43.74094083350288
Files already downloaded and verified
Files already downloaded and verified
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
CNN(
  (c1): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (c2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (c3): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fc1): Sequential(
    (0): Linear(in_features=2048, out_features=256, bias=True)
    (1): ReLU()
  )
  (last): ModuleDict(
    (1): Linear(in_features=256, out_features=2, bias=True)
    (2): Linear(in_features=256, out_features=2, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
    (5): Linear(in_features=256, out_features=2, bias=True)
  )
)
#parameter of model: 962858
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
* TRAIN - Accuracy 81.316 Loss 0.3967
* VALID - Accuracy 89.910 Loss 0.2470
Epoch:1
LR: 0.001
* TRAIN - Accuracy 89.798 Loss 0.2443
* VALID - Accuracy 91.150 Loss 0.2161
Epoch:2
LR: 0.001
* TRAIN - Accuracy 91.720 Loss 0.1997
* VALID - Accuracy 90.340 Loss 0.2397
Epoch:3
LR: 0.001
* TRAIN - Accuracy 92.870 Loss 0.1737
* VALID - Accuracy 93.570 Loss 0.1639
Epoch:4
LR: 0.001
* TRAIN - Accuracy 93.592 Loss 0.1564
* VALID - Accuracy 91.830 Loss 0.2075
Epoch:5
LR: 0.001
* TRAIN - Accuracy 94.318 Loss 0.1417
* VALID - Accuracy 93.480 Loss 0.1646
Epoch:6
LR: 0.001
* TRAIN - Accuracy 94.704 Loss 0.1296
* VALID - Accuracy 94.040 Loss 0.1619
Epoch:7
LR: 0.001
* TRAIN - Accuracy 95.318 Loss 0.1188
* VALID - Accuracy 94.080 Loss 0.1524
Epoch:8
LR: 0.001
* TRAIN - Accuracy 95.780 Loss 0.1080
* VALID - Accuracy 95.050 Loss 0.1311
Epoch:9
LR: 0.001
* TRAIN - Accuracy 95.982 Loss 0.1030
* VALID - Accuracy 95.420 Loss 0.1183
Epoch:10
LR: 0.001
* TRAIN - Accuracy 96.072 Loss 0.0998
* VALID - Accuracy 94.040 Loss 0.1481
Epoch:11
LR: 0.001
* TRAIN - Accuracy 96.568 Loss 0.0905
* VALID - Accuracy 95.470 Loss 0.1258
* VALID - Accuracy 95.470 Loss 0.1258
OrderedDict([('All', {'All': 95.47})])
Task All average acc: 95.47
===Summary of experiment repeats: 8 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [95.39 95.47 95.42 95.45 95.41 95.18 95.83 95.47  0.    0.  ]
mean: 76.362 std: 38.18129353492362
Files already downloaded and verified
Files already downloaded and verified
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
CNN(
  (c1): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (c2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (c3): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fc1): Sequential(
    (0): Linear(in_features=2048, out_features=256, bias=True)
    (1): ReLU()
  )
  (last): ModuleDict(
    (1): Linear(in_features=256, out_features=2, bias=True)
    (2): Linear(in_features=256, out_features=2, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
    (5): Linear(in_features=256, out_features=2, bias=True)
  )
)
#parameter of model: 962858
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
* TRAIN - Accuracy 82.162 Loss 0.3834
* VALID - Accuracy 81.730 Loss 0.4321
Epoch:1
LR: 0.001
* TRAIN - Accuracy 89.836 Loss 0.2416
* VALID - Accuracy 90.400 Loss 0.2188
Epoch:2
LR: 0.001
* TRAIN - Accuracy 91.992 Loss 0.1945
* VALID - Accuracy 89.010 Loss 0.2995
Epoch:3
LR: 0.001
* TRAIN - Accuracy 93.018 Loss 0.1695
* VALID - Accuracy 93.620 Loss 0.1532
Epoch:4
LR: 0.001
* TRAIN - Accuracy 93.950 Loss 0.1510
* VALID - Accuracy 92.440 Loss 0.1977
Epoch:5
LR: 0.001
* TRAIN - Accuracy 94.532 Loss 0.1365
* VALID - Accuracy 93.490 Loss 0.1644
Epoch:6
LR: 0.001
* TRAIN - Accuracy 95.022 Loss 0.1267
* VALID - Accuracy 94.760 Loss 0.1323
Epoch:7
LR: 0.001
* TRAIN - Accuracy 95.522 Loss 0.1120
* VALID - Accuracy 94.920 Loss 0.1317
Epoch:8
LR: 0.001
* TRAIN - Accuracy 95.828 Loss 0.1055
* VALID - Accuracy 94.460 Loss 0.1392
Epoch:9
LR: 0.001
* TRAIN - Accuracy 96.058 Loss 0.1013
* VALID - Accuracy 95.320 Loss 0.1234
Epoch:10
LR: 0.001
* TRAIN - Accuracy 96.406 Loss 0.0929
* VALID - Accuracy 95.440 Loss 0.1269
Epoch:11
LR: 0.001
* TRAIN - Accuracy 96.644 Loss 0.0880
* VALID - Accuracy 93.380 Loss 0.1721
* VALID - Accuracy 93.380 Loss 0.1721
OrderedDict([('All', {'All': 93.38})])
Task All average acc: 93.38
===Summary of experiment repeats: 9 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [95.39 95.47 95.42 95.45 95.41 95.18 95.83 95.47 93.38  0.  ]
mean: 85.7 std: 28.57374074215695
Files already downloaded and verified
Files already downloaded and verified
split_boundaries: [0, 2, 4, 6, 8, 10]
{'1': [0, 1], '2': [2, 3], '3': [4, 5], '4': [6, 7], '5': [8, 9]}
CNN(
  (c1): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (c2): Sequential(
    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (c3): Sequential(
    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fc1): Sequential(
    (0): Linear(in_features=2048, out_features=256, bias=True)
    (1): ReLU()
  )
  (last): ModuleDict(
    (1): Linear(in_features=256, out_features=2, bias=True)
    (2): Linear(in_features=256, out_features=2, bias=True)
    (3): Linear(in_features=256, out_features=2, bias=True)
    (4): Linear(in_features=256, out_features=2, bias=True)
    (5): Linear(in_features=256, out_features=2, bias=True)
  )
)
#parameter of model: 962858
Task order: ['1', '2', '3', '4', '5']
Epoch:0
LR: 0.001
* TRAIN - Accuracy 80.392 Loss 0.4116
* VALID - Accuracy 88.080 Loss 0.2758
Epoch:1
LR: 0.001
* TRAIN - Accuracy 88.990 Loss 0.2584
* VALID - Accuracy 89.030 Loss 0.2622
Epoch:2
LR: 0.001
* TRAIN - Accuracy 91.798 Loss 0.2000
* VALID - Accuracy 91.570 Loss 0.2073
Epoch:3
LR: 0.001
* TRAIN - Accuracy 92.936 Loss 0.1740
* VALID - Accuracy 92.410 Loss 0.1871
Epoch:4
LR: 0.001
* TRAIN - Accuracy 93.626 Loss 0.1576
* VALID - Accuracy 92.080 Loss 0.1995
Epoch:5
LR: 0.001
* TRAIN - Accuracy 94.366 Loss 0.1416
* VALID - Accuracy 93.840 Loss 0.1636
Epoch:6
LR: 0.001
* TRAIN - Accuracy 94.802 Loss 0.1300
* VALID - Accuracy 93.430 Loss 0.1699
Epoch:7
LR: 0.001
* TRAIN - Accuracy 95.298 Loss 0.1202
* VALID - Accuracy 94.790 Loss 0.1361
Epoch:8
LR: 0.001
* TRAIN - Accuracy 95.650 Loss 0.1096
* VALID - Accuracy 95.100 Loss 0.1274
Epoch:9
LR: 0.001
* TRAIN - Accuracy 95.914 Loss 0.1044
* VALID - Accuracy 94.410 Loss 0.1442
Epoch:10
LR: 0.001
* TRAIN - Accuracy 96.232 Loss 0.0960
* VALID - Accuracy 94.090 Loss 0.1708
Epoch:11
LR: 0.001
* TRAIN - Accuracy 96.398 Loss 0.0926
* VALID - Accuracy 95.570 Loss 0.1222
* VALID - Accuracy 95.570 Loss 0.1222
OrderedDict([('All', {'All': 95.57})])
Task All average acc: 95.57
===Summary of experiment repeats: 10 / 10 ===
The regularization coefficient: 0.0
The last avg acc of all repeats: [95.39 95.47 95.42 95.45 95.41 95.18 95.83 95.47 93.38 95.57]
mean: 95.25699999999999 std: 0.6442833227703485
reg_coef: 0.0 mean: 95.25699999999999 std: 0.6442833227703485
