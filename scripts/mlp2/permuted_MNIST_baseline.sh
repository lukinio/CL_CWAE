GPUID=$1
OUTDIR=outputs/mlp2/permuted_MNIST
REPEAT=10
mkdir -p $OUTDIR

# INCREMENTAL TASK
#python -u iBatchLearn.py --dataroot /shared/sets/datasets/vision --gpuid $GPUID --repeat $REPEAT --optimizer Adam    --n_permutation 10 --no_class_remap --force_out_dim 0 --schedule 10 --batch_size 128 --model_name MLP2                                                     --lr 0.0001  --offline_training    | tee ${OUTDIR}/IT_Offline.log
#python -u iBatchLearn.py --dataroot /shared/sets/datasets/vision --gpuid $GPUID --repeat $REPEAT --optimizer Adam    --n_permutation 10 --no_class_remap --force_out_dim 0 --schedule 10 --batch_size 128 --model_name MLP2                                                     --lr 0.0001                        | tee ${OUTDIR}/IT_Adam.log
#python -u iBatchLearn.py --dataroot /shared/sets/datasets/vision --gpuid $GPUID --repeat $REPEAT --optimizer SGD     --n_permutation 10 --no_class_remap --force_out_dim 0 --schedule 10 --batch_size 128 --model_name MLP2                                                     --lr 0.01                          | tee ${OUTDIR}/IT_SGD.log
#python -u iBatchLearn.py --dataroot /shared/sets/datasets/vision --gpuid $GPUID --repeat $REPEAT --optimizer Adagrad --n_permutation 10 --no_class_remap --force_out_dim 0 --schedule 10 --batch_size 128 --model_name MLP2                                                     --lr 0.001                         | tee ${OUTDIR}/IT_Adagrad.log
#python -u iBatchLearn.py --dataroot /shared/sets/datasets/vision --gpuid $GPUID --repeat $REPEAT --optimizer Adam    --n_permutation 10 --no_class_remap --force_out_dim 0 --schedule 10 --batch_size 128 --model_name MLP2 --agent_type customization  --agent_name EWC_online_mnist --lr 0.0001 --reg_coef 500   | tee ${OUTDIR}/IT_EWC_online.log
#python -u iBatchLearn.py --dataroot /shared/sets/datasets/vision --gpuid $GPUID --repeat $REPEAT --optimizer Adam    --n_permutation 10 --no_class_remap --force_out_dim 0 --schedule 10 --batch_size 128 --model_name MLP2 --agent_type customization  --agent_name EWC_mnist        --lr 0.0001 --reg_coef 500   | tee ${OUTDIR}/IT_EWC.log
#python -u iBatchLearn.py --dataroot /shared/sets/datasets/vision --gpuid $GPUID --repeat $REPEAT --optimizer Adam    --n_permutation 10 --no_class_remap --force_out_dim 0 --schedule 10 --batch_size 128 --model_name MLP2 --agent_type regularization --agent_name SI         --lr 0.0001 --reg_coef 1           | tee ${OUTDIR}/IT_SI.log
#python -u iBatchLearn.py --dataroot /shared/sets/datasets/vision --gpuid $GPUID --repeat $REPEAT --optimizer Adam    --n_permutation 10 --no_class_remap --force_out_dim 0 --schedule 10 --batch_size 128 --model_name MLP2 --agent_type regularization --agent_name L2         --lr 0.0001 --reg_coef 0.001       | tee ${OUTDIR}/IT_L2.log
#python -u iBatchLearn.py --dataroot /shared/sets/datasets/vision --gpuid $GPUID --repeat $REPEAT --optimizer Adam    --n_permutation 10 --no_class_remap --force_out_dim 0 --schedule 10 --batch_size 128 --model_name MLP2 --agent_type regularization --agent_name MAS        --lr 0.0001 --reg_coef 0.01        | tee ${OUTDIR}/IT_MAS.log


# INCREMENTAL DOMAIN
#python -u iBatchLearn.py --dataroot /shared/sets/datasets/vision --gpuid $GPUID --repeat $REPEAT --optimizer Adam    --n_permutation 10 --no_class_remap --force_out_dim 10 --schedule 10 --batch_size 128 --model_name MLP2                                                     --lr 0.0001  --offline_training  | tee ${OUTDIR}/ID_Offline.log
#python -u iBatchLearn.py --dataroot /shared/sets/datasets/vision --gpuid $GPUID --repeat $REPEAT --optimizer Adam    --n_permutation 10 --no_class_remap --force_out_dim 10 --schedule 10 --batch_size 128 --model_name MLP2                                                     --lr 0.0001                      | tee ${OUTDIR}/ID_Adam.log
#python -u iBatchLearn.py --dataroot /shared/sets/datasets/vision --gpuid $GPUID --repeat $REPEAT --optimizer SGD     --n_permutation 10 --no_class_remap --force_out_dim 10 --schedule 10 --batch_size 128 --model_name MLP2                                                     --lr 0.001                       | tee ${OUTDIR}/ID_SGD.log
#python -u iBatchLearn.py --dataroot /shared/sets/datasets/vision --gpuid $GPUID --repeat $REPEAT --optimizer Adagrad --n_permutation 10 --no_class_remap --force_out_dim 10 --schedule 10 --batch_size 128 --model_name MLP2                                                     --lr 0.001                       | tee ${OUTDIR}/ID_Adagrad.log
#python -u iBatchLearn.py --dataroot /shared/sets/datasets/vision --gpuid $GPUID --repeat $REPEAT --optimizer Adam    --n_permutation 10 --no_class_remap --force_out_dim 10 --schedule 10 --batch_size 128 --model_name MLP2 --agent_type customization  --agent_name EWC_online --lr 0.0001 --reg_coef 250       | tee ${OUTDIR}/ID_EWC_online.log
#python -u iBatchLearn.py --dataroot /shared/sets/datasets/vision --gpuid $GPUID --repeat $REPEAT --optimizer Adam    --n_permutation 10 --no_class_remap --force_out_dim 10 --schedule 10 --batch_size 128 --model_name MLP2 --agent_type customization  --agent_name EWC        --lr 0.0001 --reg_coef 150       | tee ${OUTDIR}/ID_EWC.log
#python -u iBatchLearn.py --dataroot /shared/sets/datasets/vision --gpuid $GPUID --repeat $REPEAT --optimizer Adam    --n_permutation 10 --no_class_remap --force_out_dim 10 --schedule 10 --batch_size 128 --model_name MLP2 --agent_type regularization --agent_name SI         --lr 0.0001 --reg_coef 10        | tee ${OUTDIR}/ID_SI.log
#python -u iBatchLearn.py --dataroot /shared/sets/datasets/vision --gpuid $GPUID --repeat $REPEAT --optimizer Adam    --n_permutation 10 --no_class_remap --force_out_dim 10 --schedule 10 --batch_size 128 --model_name MLP2 --agent_type regularization --agent_name L2         --lr 0.0001 --reg_coef 0.02      | tee ${OUTDIR}/ID_L2.log
python -u iBatchLearn.py --dataroot /shared/sets/datasets/vision --gpuid $GPUID --repeat $REPEAT --optimizer Adam    --n_permutation 10 --no_class_remap --force_out_dim 10 --schedule 10 --batch_size 128 --model_name MLP2 --agent_type regularization --agent_name MAS        --lr 0.0001 --reg_coef 0.1       | tee ${OUTDIR}/ID_MAS.log


# INCREMENTAL CLASS
#python -u iBatchLearn.py --dataroot /shared/sets/datasets/vision --gpuid $GPUID --repeat $REPEAT --incremental_class --optimizer Adam    --n_permutation 10 --force_out_dim 100 --schedule 10 --batch_size 128 --model_name MLP2                                                     --lr 0.0001  --offline_training  | tee ${OUTDIR}/Offline.log
#python -u iBatchLearn.py --dataroot /shared/sets/datasets/vision --gpuid $GPUID --repeat $REPEAT --incremental_class --optimizer Adam    --n_permutation 10 --force_out_dim 100 --schedule 10 --batch_size 128 --model_name MLP2                                                     --lr 0.0001                      | tee ${OUTDIR}/Adam.log
#python -u iBatchLearn.py --dataroot /shared/sets/datasets/vision --gpuid $GPUID --repeat $REPEAT --incremental_class --optimizer SGD     --n_permutation 10 --force_out_dim 100 --schedule 10 --batch_size 128 --model_name MLP2                                                     --lr 0.001                       | tee ${OUTDIR}/SGD.log
#python -u iBatchLearn.py --dataroot /shared/sets/datasets/vision --gpuid $GPUID --repeat $REPEAT --incremental_class --optimizer Adagrad --n_permutation 10 --force_out_dim 100 --schedule 10 --batch_size 128 --model_name MLP2                                                     --lr 0.001                       | tee ${OUTDIR}/Adagrad.log
#python -u iBatchLearn.py --dataroot /shared/sets/datasets/vision --gpuid $GPUID --repeat $REPEAT --incremental_class --optimizer Adam    --n_permutation 10 --force_out_dim 100 --schedule 10 --batch_size 128 --model_name MLP2 --agent_type customization  --agent_name EWC_online_mnist --lr 0.0001 --reg_coef 50  | tee ${OUTDIR}/EWC_online.log
#python -u iBatchLearn.py --dataroot /shared/sets/datasets/vision --gpuid $GPUID --repeat $REPEAT --incremental_class --optimizer Adam    --n_permutation 10 --force_out_dim 100 --schedule 10 --batch_size 128 --model_name MLP2 --agent_type customization  --agent_name EWC_mnist        --lr 0.0001 --reg_coef 10  | tee ${OUTDIR}/EWC.log
#python -u iBatchLearn.py --dataroot /shared/sets/datasets/vision --gpuid $GPUID --repeat $REPEAT --incremental_class --optimizer Adam    --n_permutation 10 --force_out_dim 100 --schedule 10 --batch_size 128 --model_name MLP2 --agent_type regularization --agent_name SI         --lr 0.0001 --reg_coef 0.3       | tee ${OUTDIR}/SI.log
#python -u iBatchLearn.py --dataroot /shared/sets/datasets/vision --gpuid $GPUID --repeat $REPEAT --incremental_class --optimizer Adam    --n_permutation 10 --force_out_dim 100 --schedule 10 --batch_size 128 --model_name MLP2 --agent_type regularization --agent_name L2         --lr 0.0001 --reg_coef 0         | tee ${OUTDIR}/L2.log
#python -u iBatchLearn.py --dataroot /shared/sets/datasets/vision --gpuid $GPUID --repeat $REPEAT --incremental_class --optimizer Adam    --n_permutation 10 --force_out_dim 100 --schedule 10 --batch_size 128 --model_name MLP2 --agent_type regularization --agent_name MAS        --lr 0.0001 --reg_coef 0.003     | tee ${OUTDIR}/MAS.log
